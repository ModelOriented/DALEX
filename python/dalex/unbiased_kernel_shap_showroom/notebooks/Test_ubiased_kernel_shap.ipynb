{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data definition](data_dict.png \"Data definition\")\n",
    "\n",
    "To calculate exact shapley values we decided to remove some features and leave 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rk4Z8HUQ122V",
    "outputId": "67cd4b3b-9b1a-44c5-8b3d-a4bbb32c9583"
   },
   "outputs": [],
   "source": [
    "# !pip install -e ../\n",
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ierrZyf9RUzT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import dalex as dx\n",
    "import time\n",
    "import numpy as np\n",
    "import shap\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "ESTIMATES_DIR = Path.cwd().parent / \"estimates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uCqVNapzT2kE"
   },
   "outputs": [],
   "source": [
    "df_titanic_train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
    "df_titanic_test_x = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "df_test_target_unordered = pd.read_csv(DATA_DIR / \"gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYnmSIr0UIbb",
    "outputId": "1d58d291-2153-40cf-9405-3a8fd67fc9e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_titanic_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RrTBpQ93UXFj"
   },
   "outputs": [],
   "source": [
    "df_titanic_train = pd.read_csv(DATA_DIR / \"train.csv\")\n",
    "df_titanic_test_x = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "df_test_target_unordered = pd.read_csv(DATA_DIR / \"gender_submission.csv\")\n",
    "\n",
    "# irrelevant features\n",
    "df_titanic_train = df_titanic_train.drop(\n",
    "    columns=[\"Name\", \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    ").dropna()\n",
    "df_titanic_test_x = df_titanic_test_x.drop(\n",
    "    columns=[\"Name\", \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    ").dropna()\n",
    "\n",
    "df_titanic_train_y = df_titanic_train[\"Survived\"]\n",
    "df_titanic_train_x = df_titanic_train.drop(columns=[\"PassengerId\", \"Survived\"])\n",
    "\n",
    "df_titanic_train_x[\"Sex\"] = df_titanic_train_x[\"Sex\"].map({\"female\": 0, \"male\": 1})\n",
    "df_titanic_test_x[\"Sex\"] = df_titanic_test_x[\"Sex\"].map({\"female\": 0, \"male\": 1})\n",
    "\n",
    "# one-hot-encoding of Pclass\n",
    "for class_nb in range(1, 4):\n",
    "    df_titanic_train_x[f\"Pclass_{class_nb}\"] = (\n",
    "        df_titanic_train_x[\"Pclass\"] == class_nb\n",
    "    ) * 1\n",
    "    df_titanic_test_x[f\"Pclass_{class_nb}\"] = (\n",
    "        df_titanic_test_x[\"Pclass\"] == class_nb\n",
    "    ) * 1\n",
    "\n",
    "df_titanic_train_x = df_titanic_train_x.drop(columns=\"Pclass\")\n",
    "df_titanic_test_x = df_titanic_test_x.drop(columns=\"Pclass\")\n",
    "\n",
    "df_titanic_test = df_test_target_unordered.merge(\n",
    "    df_titanic_test_x, how=\"inner\", on=\"PassengerId\"\n",
    ")\n",
    "df_titanic_test_y = df_titanic_test[\"Survived\"]\n",
    "df_titanic_test_x = df_titanic_test.drop(columns=[\"PassengerId\", \"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic_train_x.columns == df_titanic_test_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Pclass_1', 'Pclass_2',\n",
       "       'Pclass_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic_train_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "yeX__GlCYBv7",
    "outputId": "980a3117-7073-4052-9b43-9a8620977cc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "326    1\n",
       "327    1\n",
       "328    1\n",
       "329    1\n",
       "330    0\n",
       "Name: Survived, Length: 331, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zPyq5jHID2Q",
    "outputId": "f7635e22-0a42-426c-ca0f-20b2553fb6b4"
   },
   "outputs": [],
   "source": [
    "model_predicting_method = lambda m, d: m.predict_proba(d)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXR2tt7GBD-e",
    "outputId": "fb083e49-9f8c-4efd-dccd-583ca1a0d294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 331 rows 8 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 331 values\n",
      "  -> model_class       : sklearn.ensemble._forest.RandomForestClassifier (default)\n",
      "  -> label             : RF\n",
      "  -> predict function  : <function <lambda> at 0x7ff17ec8d950> will be used\n",
      "  -> predict function  : Accepts pandas.DataFrame and numpy.ndarray.\n",
      "  -> predicted values  : min = 0.107, mean = 0.427, max = 0.945\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.758, mean = -0.0433, max = 0.812\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=300, max_depth=5, random_state=446519)\n",
    "rf.fit(df_titanic_train_x, df_titanic_train_y)\n",
    "explainer_rf = dx.Explainer(\n",
    "    rf,\n",
    "    df_titanic_test_x,\n",
    "    df_titanic_test_y,\n",
    "    predict_function=model_predicting_method,\n",
    "    label=\"RF\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mI8vF6K5B9s8",
    "outputId": "dbcd7cbe-1d37-45f1-c982-180586c51345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 331 rows 8 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 331 values\n",
      "  -> model_class       : sklearn.svm._classes.SVC (default)\n",
      "  -> label             : SVC\n",
      "  -> predict function  : <function <lambda> at 0x7ff17ec8d950> will be used\n",
      "  -> predict function  : Accepts pandas.DataFrame and numpy.ndarray.\n",
      "  -> predicted values  : min = 0.281, mean = 0.419, max = 0.779\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.778, mean = -0.0354, max = 0.719\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but SVC was fitted with feature names\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state=446519, probability=True)\n",
    "svc.fit(df_titanic_train_x, df_titanic_train_y)\n",
    "explainer_svc = dx.Explainer(\n",
    "    svc,\n",
    "    df_titanic_test_x,\n",
    "    df_titanic_test_y,\n",
    "    predict_function=model_predicting_method,\n",
    "    label=\"SVC\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0KP_x9Ab04s",
    "outputId": "804dfabc-d8af-4811-85b2-15fd60dd861a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 331 rows 8 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 331 values\n",
      "  -> model_class       : sklearn.linear_model._logistic.LogisticRegression (default)\n",
      "  -> label             : LR\n",
      "  -> predict function  : <function <lambda> at 0x7ff17ec8d950> will be used\n",
      "  -> predict function  : Accepts pandas.DataFrame and numpy.ndarray.\n",
      "  -> predicted values  : min = 0.014, mean = 0.433, max = 0.962\n",
      "  -> model type        : classification will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -0.795, mean = -0.0497, max = 0.821\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "X does not have valid feature names, but LogisticRegression was fitted with feature names\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=446519)\n",
    "lr.fit(df_titanic_train_x, df_titanic_train_y)\n",
    "explainer_lr = dx.Explainer(\n",
    "    lr,\n",
    "    df_titanic_test_x,\n",
    "    df_titanic_test_y,\n",
    "    predict_function=model_predicting_method,\n",
    "    label=\"LR\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_titanic_test_x.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "9Cg2uKyScEel",
    "outputId": "3f30665a-6a1d-462c-9156-1b73a2655549"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "displaylogo": false,
        "modeBarButtonsToRemove": [
         "sendDataToCloud",
         "lasso2d",
         "autoScale2d",
         "select2d",
         "zoom2d",
         "pan2d",
         "zoomIn2d",
         "zoomOut2d",
         "resetScale2d",
         "toggleSpikelines",
         "hoverCompareCartesian",
         "hoverClosestCartesian"
        ],
        "plotlyServerURL": "https://plot.ly",
        "staticPlot": false,
        "toImageButtonOptions": {
         "height": null,
         "width": null
        }
       },
       "data": [
        {
         "base": 0.3922652930675453,
         "hoverinfo": "text",
         "hoverlabel": {
          "bgcolor": "rgba(0,0,0,0.8)"
         },
         "hovertext": [
          "Average response: 0.392<br>Prediction: 0.122<br>Sex = 1.0<br>decreases average response <br>by 0.08",
          "Average response: 0.392<br>Prediction: 0.122<br>Fare = 7.829<br>decreases average response <br>by 0.078",
          "Average response: 0.392<br>Prediction: 0.122<br>Pclass_3 = 1.0<br>decreases average response <br>by 0.057",
          "Average response: 0.392<br>Prediction: 0.122<br>Parch = 0.0<br>decreases average response <br>by 0.023",
          "Average response: 0.392<br>Prediction: 0.122<br>Age = 34.5<br>decreases average response <br>by 0.023",
          "Average response: 0.392<br>Prediction: 0.122<br>Pclass_1 = 0.0<br>decreases average response <br>by 0.019",
          "Average response: 0.392<br>Prediction: 0.122<br>SibSp = 0.0<br>increases average response <br>by 0.012",
          "Average response: 0.392<br>Prediction: 0.122<br>Pclass_2 = 0.0<br>decreases average response <br>by 0.004"
         ],
         "marker": {
          "color": [
           "#f05a71",
           "#f05a71",
           "#f05a71",
           "#f05a71",
           "#f05a71",
           "#f05a71",
           "#8bdcbe",
           "#f05a71"
          ]
         },
         "orientation": "h",
         "showlegend": false,
         "text": [
          "-0.08",
          "-0.078",
          "-0.057",
          "-0.023",
          "-0.023",
          "-0.019",
          "+0.012",
          "-0.004"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          -0.08,
          -0.078,
          -0.057,
          -0.023,
          -0.023,
          -0.019,
          0.012,
          -0.004
         ],
         "xaxis": "x",
         "y": [
          "Sex = 1.0",
          "Fare = 7.829",
          "Pclass_3 = 1.0",
          "Parch = 0.0",
          "Age = 34.5",
          "Pclass_1 = 0.0",
          "SibSp = 0.0",
          "Pclass_2 = 0.0"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "sample id: 0",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "contribution",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0,
          "yanchor": "top",
          "yref": "paper",
          "yshift": -30
         }
        ],
        "font": {
         "color": "#371ea3"
        },
        "height": 313,
        "margin": {
         "b": 71,
         "r": 30,
         "t": 78
        },
        "shapes": [
         {
          "line": {
           "color": "#371ea3",
           "dash": "dot",
           "width": 1.5
          },
          "type": "line",
          "x0": 0.3922652930675453,
          "x1": 0.3922652930675453,
          "xref": "x",
          "y0": -1,
          "y1": 8,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "scatter": [
           {
            "type": "scatter"
           }
          ]
         }
        },
        "title": {
         "text": "Shapley Values",
         "x": 0.15
        },
        "xaxis": {
         "anchor": "y",
         "automargin": true,
         "domain": [
          0,
          1
         ],
         "fixedrange": true,
         "gridwidth": 2,
         "range": [
          0.2984652930675453,
          0.4180652930675453
         ],
         "tickcolor": "white",
         "ticklen": 3,
         "ticks": "outside",
         "type": "linear",
         "zeroline": false
        },
        "yaxis": {
         "anchor": "x",
         "automargin": true,
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "fixedrange": true,
         "gridwidth": 2,
         "tickcolor": "white",
         "ticklen": 10,
         "ticks": "outside",
         "type": "category"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explainer_rf.predict_parts(\n",
    "    df_titanic_test_x.iloc[0:1], type=\"unbiased_kernel_shap\", label=f\"sample id: 0\"\n",
    ").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UWAGA! Poniższa komórka była odpalona raz a jej wyniki zostały zapisane do plików. Wystarczy zmienne załadować z pliku :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_of_explainers = {\"random_forrest\":explainer_rf,\n",
    "#                       \"support_vector_machine\": explainer_svc,\n",
    "#                       \"logistic_regression\": explainer_lr}\n",
    "# list_of_n_samples = [10, 50, 100, 500, 1000]\n",
    "\n",
    "# times_uks = np.zeros((len(dict_of_explainers), len(list_of_n_samples)))\n",
    "\n",
    "# for e_id, (exp_name, explainer) in enumerate(dict_of_explainers.items()):\n",
    "#     for s_id, n_samples in enumerate(list_of_n_samples):\n",
    "\n",
    "#         start = time.time()\n",
    "\n",
    "#         explained = df_titanic_test_x.apply(lambda x: explainer.predict_parts(x.to_frame().transpose(),\n",
    "#                                                              type=\"unbiased_kernel_shap\",\n",
    "#                                                              n_samples = n_samples), axis=1)\n",
    "\n",
    "#         end = time.time()\n",
    "\n",
    "#         result = explained.apply(lambda x: x.result.contribution.to_numpy()).to_numpy()\n",
    "\n",
    "#         np.save(EXTIMATES_DIR / f\"{exp_name}_{n_samples}.npy\", result)\n",
    "\n",
    "#         process_time = end - start\n",
    "#         times_uks[e_id][s_id] = process_time\n",
    "\n",
    "# np.save(EXTIMATES_DIR / \"times_uks.npy\", times_uks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact_explainer_rf = shap.explainers.Exact(rf.predict_proba, df_titanic_test_x)\n",
    "# exact_explainer_svc = shap.explainers.Exact(svc.predict_proba, df_titanic_test_x)\n",
    "# exact_explainer_lr = shap.explainers.Exact(lr.predict_proba, df_titanic_test_x)\n",
    "\n",
    "# dict_of_explainers = {\"random_forrest\":exact_explainer_rf,\n",
    "#                       \"support_vector_machine\": exact_explainer_svc,\n",
    "#                       \"logistic_regression\": exact_explainer_lr}\n",
    "\n",
    "# times_uks = np.zeros((len(dict_of_explainers),))\n",
    "\n",
    "# for e_id, (exp_name, explainer) in enumerate(dict_of_explainers.items()):\n",
    "\n",
    "#         start = time.time()\n",
    "\n",
    "#         shap_values = explainer(df_titanic_test_x)\n",
    "\n",
    "#         end = time.time()\n",
    "\n",
    "#         result = shap_values.values[...,1]\n",
    "\n",
    "#         np.save(EXTIMATES_DIR / f\"{exp_name}_exact.npy\", result)\n",
    "\n",
    "#         process_time = end - start\n",
    "#         times_uks[e_id] = process_time\n",
    "\n",
    "# np.save(EXTIMATES_DIR / \"times_exact.npy\", times_uks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact_explainer_rf = shap.KernelExplainer(rf.predict_proba, df_titanic_test_x)\n",
    "# exact_explainer_svc = shap.KernelExplainer(svc.predict_proba, df_titanic_test_x)\n",
    "# exact_explainer_lr = shap.KernelExplainer(lr.predict_proba, df_titanic_test_x)\n",
    "\n",
    "# dict_of_explainers = {\"random_forrest\":exact_explainer_rf,\n",
    "#                       \"support_vector_machine\": exact_explainer_svc,\n",
    "#                       \"logistic_regression\": exact_explainer_lr}\n",
    "\n",
    "# times_uks = np.zeros((len(dict_of_explainers),))\n",
    "\n",
    "# for e_id, (exp_name, explainer) in enumerate(dict_of_explainers.items()):\n",
    "\n",
    "#         start = time.time()\n",
    "\n",
    "#         shap_values = explainer.shap_values(df_titanic_test_x)\n",
    "\n",
    "#         end = time.time()\n",
    "\n",
    "#         result = shap_values[1]\n",
    "\n",
    "#         np.save(EXTIMATES_DIR / f\"{exp_name}_kernel.npy\", result)\n",
    "\n",
    "#         process_time = end - start\n",
    "#         times_uks[e_id] = process_time\n",
    "\n",
    "# np.save(EXTIMATES_DIR / \"times_kernel.npy\", times_uks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('dalex')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9b7f736565c6cd40b8d49336405822da11305b97b415f12dc2975a61ae6e90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
